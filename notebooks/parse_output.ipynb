{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35eb83-8425-41f4-9cb0-3f4cb632a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87740871-5b58-49a0-bbb7-9a98162f142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../source/\")\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e0352-9f3e-4a50-8d71-180097cf801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.track_progress import timefmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3d9d0-f2e7-482b-927e-6c0b6cb0eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e283497-7f7c-4c24-bd1b-0c91a740a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"/envroot/trainings/camera_train\")\n",
    "cmd_dir = root_dir / \"collected_commands\"\n",
    "pos_dir = root_dir / \"collected_positions\"\n",
    "embed_dir = root_dir / \"collected_embeds\"\n",
    "img_dir = root_dir / \"collected_imgs\"\n",
    "\n",
    "wm_dir = root_dir / \"world_models\"\n",
    "ag_dir = root_dir / \"agents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cf0bf-eacc-49b5-b554-9dd1e8521924",
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_file = root_dir / \"progress_model_names.txt\"\n",
    "with open(prog_file, \"r\") as f:\n",
    "    models, timestamps = list(zip(*[map(str.strip, l.strip().split(\"@\")) for l in f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbf055-f016-44ff-a634-9c2275549d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. sort the model by the images\n",
    "# 2. train image paths\n",
    "# 3. parse the wm, agent, image used to train the model, image capture by the agent\n",
    "import yaml\n",
    "from source.datasets.ptz_dataset import get_position_datetime_from_labels\n",
    "import numpy as np\n",
    "import pprint\n",
    "import copy\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ModelInfo:\n",
    "    def __init__(self, model_basedir, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = Path(model_basedir, model_name)\n",
    "        model_info_path = self.model_dir / \"model_info.yaml\"\n",
    "        with open(model_info_path, \"r\") as f:\n",
    "            self.info_dict = yaml.safe_load(f)\n",
    "        self.ori_info_dict = copy.deepcopy(self.info_dict)\n",
    "        imgnames = np.array(os.listdir(img_dir))\n",
    "        imgposs, imgtimes = get_position_datetime_from_labels([iname.strip(\".jpg\") for iname in imgnames])\n",
    "        # imgtimes = pd.to_datetime(imgtimes, format=timefmt)\n",
    "        # figure out images that are used in the trainings\n",
    "        for k in self.info_dict.keys():\n",
    "            if not k.startswith(\"restart_\"):\n",
    "                continue\n",
    "            restart_dict = self.info_dict[k]\n",
    "            if len(restart_dict[\"images\"][\"start_end\"]) == 2:\n",
    "                starttime, endtime = pd.to_datetime(restart_dict[\"images\"][\"start_end\"], format=timefmt, utc=True)\n",
    "                idx = np.where((starttime <= imgtimes) & (imgtimes <= endtime))[0]\n",
    "            else:\n",
    "                # is an agent and was used for more than once to get images\n",
    "                idx = []\n",
    "                timedata = restart_dict[\"images\"][\"start_end\"]\n",
    "                for i in range(len(timedata) // 2):\n",
    "                    # print(timedata[i*2:i*2+1])\n",
    "                    starttime, endtime = pd.to_datetime(timedata[i*2:i*2+2], format=timefmt, utc=True)\n",
    "                    idx.append(np.where((starttime <= imgtimes) & (imgtimes <= endtime))[0])\n",
    "                # print(type(starttime), type(imgtimes))\n",
    "                idx = np.stack(idx)\n",
    "            restart_dict[\"images\"][\"filename\"] = imgnames[idx]\n",
    "\n",
    "    def __repr__(self):\n",
    "        from pprint import pformat\n",
    "        return pformat(self.ori_info_dict)\n",
    "        # return repr(self.info_dict)\n",
    "\n",
    "    def get_images_at_restart(self, restart_iter: int):\n",
    "        if restart_iter > self.info_dict['num_restart']:\n",
    "            raise ValueError(\"Current restart of the model is smaller than the input restart iteration, check again\")\n",
    "        return self.info_dict[f\"restart_{restart_iter:0>2}\"][\"images\"][\"filename\"]\n",
    "\n",
    "\n",
    "class WorldModelInfo(ModelInfo):\n",
    "    def __init__(self, root_dir, model_name):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        wm_dir = self.root_dir / \"world_models\"\n",
    "        model_type_infer = model_name.split(\"_\")[0]\n",
    "        assert model_type_infer == \"wm\", f\"Requires a world model (wm_*), but got {model_type_infer}\"\n",
    "        super().__init__(wm_dir, model_name)\n",
    "        self.model_path = self.model_dir / \"jepa-latest.pt\"\n",
    "\n",
    "\n",
    "class AgentInfo(ModelInfo):\n",
    "    def __init__(self, root_dir, model_name):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        ag_dir = self.root_dir / \"agents\"\n",
    "        model_type_infer = model_name.split(\"_\")[0]\n",
    "        assert model_type_infer == \"ag\", f\"Requires an agent (ag_*), but got {model_type_infer}\"\n",
    "        super().__init__(ag_dir, model_name)\n",
    "        self._get_collected_timestamps()\n",
    "        self.model_target_path = self.model_dir / \"jepa-target_latest.pt\"\n",
    "        self.model_policy_path = self.model_dir / \"jepa-policy_latest.pt\"\n",
    "        \n",
    "\n",
    "    def _get_collected_timestamps(self):\n",
    "        # ! this requires all collected pos, cmd, embed have the same timestamp\n",
    "        if not (self.root_dir / \"collected_positions\").exists():\n",
    "            logger.warning(\"No timestamps found, cannot analyze collected data info\")\n",
    "            return None\n",
    "        # positions_at_2024-07-31_17:36:08.173102.txt\n",
    "        fnames = os.listdir(self.root_dir / \"collected_positions\")\n",
    "        ftimes = pd.to_datetime([fn.split(\"_at_\")[-1].strip().strip(\".txt\") for fn in fnames], format=timefmt, utc=True)\n",
    "        for k in self.info_dict.keys():\n",
    "            if not k.startswith(\"restart_\"):\n",
    "                continue\n",
    "            idx = []\n",
    "            restart_dict = self.info_dict[k]\n",
    "            if \"meta\" not in restart_dict.keys():\n",
    "                restart_dict[\"meta\"] = {}\n",
    "            timedata = restart_dict[\"images\"][\"start_end\"]\n",
    "            for i in range(len(timedata) // 2):\n",
    "                # print(timedata[i*2:i*2+1])\n",
    "                starttime, endtime = pd.to_datetime(timedata[i*2:i*2+2], format=timefmt, utc=True)\n",
    "                idx.append(np.where((starttime <= ftimes) & (ftimes <= endtime))[0])\n",
    "            # print(type(starttime), type(imgtimes))\n",
    "            idx = np.stack(idx)\n",
    "            restart_dict[\"meta\"][\"collect_timestamp\"] = np.array(ftimes.strftime(timefmt))[idx]\n",
    "\n",
    "    def get_collected_data_at_restart(self, restart_iter: int):\n",
    "        # pos, cmd, embeds\n",
    "        if restart_iter > self.info_dict['num_restart']:\n",
    "            raise ValueError(f\"Current restart of the model is smaller than the input restart iteration. Max iteration is {self.info_dict['num_restart']}\")\n",
    "        collts = self.info_dict[f\"restart_{restart_iter:0>2}\"][\"meta\"][\"collect_timestamp\"]\n",
    "        return list(zip(*[(f\"positions_at_{ts}.txt\", f\"commands_at_{ts}.txt\", f\"embeds_at_{ts}.pt\") for ts in collts.ravel()]))\n",
    "\n",
    "    def load_collected_data(self, restart_iter):\n",
    "        fnpos, fncmd, fnembed = self.get_collected_data_at_restart(restart_iter)\n",
    "        embed_dir = self.root_dir / \"collected_embeds\"\n",
    "        pos_dir = self.root_dir / \"collected_positions\"\n",
    "        cmd_dir = self.root_dir / \"collected_commands\"\n",
    "        li_embed = []\n",
    "        li_pos = []\n",
    "        li_cmd = []\n",
    "        for i in range(len(fnpos)):\n",
    "            embed = torch.load(embed_dir / fnembed[i])\n",
    "            with open(pos_dir / fnpos[i], \"r\") as f:\n",
    "                pos = np.array([l.strip().split(\",\") for l in f], dtype=float)\n",
    "            with open(cmd_dir / fncmd[i], \"r\") as f:\n",
    "                cmd = np.array([l.strip().split(\",\") for l in f], dtype=float)\n",
    "            li_embed.append(embed)\n",
    "            li_pos.append(pos)\n",
    "            li_cmd.append(cmd)\n",
    "        return li_pos, li_cmd, li_embed\n",
    "\n",
    "\n",
    "class ProgressTracker:\n",
    "    # steps:\n",
    "    # 1. train a random world model\n",
    "    # 2. generate dreams by a random trained world model\n",
    "    # 3. train a random agent (needs to stick to a single world model)\n",
    "    # 4. gather images using a random trained agent\n",
    "    # last line is always the last model name\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.prog_file = self.root_dir / \"progress_model_names.txt\"\n",
    "        with open(self.prog_file, \"r\") as f:\n",
    "            self.model_names, self.finish_time = list(zip(*[map(str.strip, l.split(\"@\")) for l in f]))\n",
    "        \n",
    "\n",
    "    # def get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ff2ea-02a0-442c-81d9-6e6ff11f276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = Path(\"/envroot/trainings/camera_train\")\n",
    "# model_name = \"wm_00_06\"\n",
    "# wm_dir = root_dir / \"world_models\"\n",
    "# model_info_path = wm_dir / model_name / \"model_info.yaml\"\n",
    "# with open(model_info_path, \"r\") as f:\n",
    "#     info_dict = yaml.safe_load(f)\n",
    "# imgnames = np.array(os.listdir(img_dir))\n",
    "# imgposs, imgtimes = get_position_datetime_from_labels([iname.strip(\".jpg\") for iname in imgnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d49ba6-7603-4967-b873-f8251b57cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AgentInfo(root_dir, \"ag_00_26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63d7e3-068e-49d8-8290-b1d3f5545c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2873e-6310-431e-9638-0e9f579faab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = WorldModelInfo(root_dir, ag.info_dict[\"restart_00\"][\"parent_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd8cf6-a52b-4e0c-bf48-b77a3cdffde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26554a-ecf4-409f-9abd-d31871cb1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ag.model_dir / \"params-agent.yaml\", \"r\") as f:\n",
    "    params = yaml.safe_load(f)\n",
    "model_arch = params['meta']['agent_model_arch']\n",
    "pred_depth = params['meta']['pred_depth']\n",
    "pred_emb_dim = params['meta']['pred_emb_dim']\n",
    "camerabrand = params['meta']['camera_brand']\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "# -- DATA\n",
    "use_gaussian_blur = params['data']['use_gaussian_blur']\n",
    "use_horizontal_flip = params['data']['use_horizontal_flip']\n",
    "use_color_distortion = params['data']['use_color_distortion']\n",
    "color_jitter = params['data']['color_jitter_strength']\n",
    "# --\n",
    "crop_size = params['data']['crop_size']\n",
    "crop_scale = params['data']['crop_scale']\n",
    "\n",
    "# -- MASK\n",
    "patch_size = params['mask']['patch_size']  # patch-size for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7871e2f-d834-4668-932a-baae8df8eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ACTIONS\n",
    "action_noop = params['action']['noop']\n",
    "action_short_left = params['action']['short']['left']\n",
    "action_short_right = params['action']['short']['right']\n",
    "action_short_left_up = params['action']['short']['left_up']\n",
    "action_short_right_up = params['action']['short']['right_up']\n",
    "action_short_left_down = params['action']['short']['left_down']\n",
    "action_short_right_down = params['action']['short']['right_down']\n",
    "action_short_up = params['action']['short']['up']\n",
    "action_short_down = params['action']['short']['down']\n",
    "action_short_zoom_in = params['action']['short']['zoom_in']\n",
    "action_short_zoom_out = params['action']['short']['zoom_out']\n",
    "\n",
    "action_long_left = params['action']['long']['left']\n",
    "action_long_right = params['action']['long']['right']\n",
    "action_long_up = params['action']['long']['up']\n",
    "action_long_down = params['action']['long']['down']\n",
    "action_long_zoom_in = params['action']['long']['zoom_in']\n",
    "action_long_zoom_out = params['action']['long']['zoom_out']\n",
    "\n",
    "action_jump_left = params['action']['jump']['left']\n",
    "action_jump_right = params['action']['jump']['right']\n",
    "action_jump_up = params['action']['jump']['up']\n",
    "action_jump_down = params['action']['jump']['down']\n",
    "\n",
    "actions={}\n",
    "actions[0]=action_noop\n",
    "actions[1]=action_short_left\n",
    "actions[2]=action_short_right\n",
    "actions[3]=action_short_left_up\n",
    "actions[4]=action_short_right_up\n",
    "actions[5]=action_short_left_down\n",
    "actions[6]=action_short_right_down\n",
    "actions[7]=action_short_up\n",
    "actions[8]=action_short_down\n",
    "actions[9]=action_short_zoom_in\n",
    "actions[10]=action_short_zoom_out\n",
    "actions[11]=action_long_left\n",
    "actions[12]=action_long_right\n",
    "actions[13]=action_long_up\n",
    "actions[14]=action_long_down\n",
    "actions[15]=action_long_zoom_in\n",
    "actions[16]=action_long_zoom_out\n",
    "actions[17]=action_jump_left\n",
    "actions[18]=action_jump_right\n",
    "actions[19]=action_jump_up\n",
    "actions[20]=action_jump_down\n",
    "\n",
    "num_actions=len(actions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7eb037-9746-407f-a8d0-ce6ebf45aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.helper import init_world_model, load_checkpoint, init_agent_model\n",
    "from source.utils.analysis_viz import scale_pca_tsne_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae20605-ce09-47e0-94c7-cb23dc214209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- init world model\n",
    "target_encoder, _ = init_world_model(\n",
    "    device=device,\n",
    "    patch_size=patch_size,\n",
    "    crop_size=crop_size,\n",
    "    pred_depth=pred_depth,\n",
    "    pred_emb_dim=pred_emb_dim,\n",
    "    model_arch=model_arch)\n",
    "\n",
    "for p in target_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# -- load training checkpoint\n",
    "_, _, target_encoder, _, _, _ = load_checkpoint(\n",
    "device=device,\n",
    "r_path=wm.model_path,\n",
    "target_encoder=target_encoder)\n",
    "\n",
    "\n",
    "_, target_predictor = init_agent_model(\n",
    "    device=device,\n",
    "    patch_size=patch_size,\n",
    "    crop_size=crop_size,\n",
    "    pred_depth=pred_depth,\n",
    "    pred_emb_dim=pred_emb_dim,\n",
    "    model_arch=model_arch,\n",
    "    num_actions=num_actions)\n",
    "\n",
    "for p in target_predictor.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# -- load training checkpoint\n",
    "_, target_predictor, _, _, _, _ = load_checkpoint(\n",
    "    device=device,\n",
    "    r_path=ag.model_target_path,\n",
    "    predictor=target_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8341a31-c68e-473b-a8fa-4febf97760bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, cmd, embed = ag.load_collected_data(1)\n",
    "\n",
    "len(pos), len(cmd), len(embed)\n",
    "# remove the last postion, where the reward is not used to guide the camera\n",
    "# pos = [p[:-1] for p in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc2571-8f08-4f65-b5d4-2ecb66ba7623",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_rewards = [target_predictor(embed[i].to(device), torch.tensor(pos[i][:-1]).to(device, dtype=torch.float32)) for i in range(len(pos))]\n",
    "action_rewards = torch.vstack(action_rewards).cpu().numpy()\n",
    "rewards = np.max(action_rewards, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31560c-4826-489b-86d6-218cf3e74edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embeds = [torch.mean(embed[i], axis=1) for i in range(len(embed))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e1aa2-2690-4335-bbd7-e76a63e670a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_tsne, embed_pca = scale_pca_tsne_transform(torch.vstack(target_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce3b1a8-51c4-48a2-9515-256300e70786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd6852-b42c-4e98-9803-cf4d34c83a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [p[:-1] for p in pos]\n",
    "pos = np.vstack(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad2838-cd92-4846-b25e-53404937697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ab9c9-17ae-491e-be44-3cf8ac8ffaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de9409-0612-4bb0-8c20-5de2d241de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "vmin = np.quantile(rewards, 0.1)\n",
    "vmax = np.quantile(rewards, 0.9)\n",
    "plt.scatter(embed_tsne[:, 0], embed_tsne[:, 1], s=2,\n",
    "              c=rewards, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"tSNE axis-1\")\n",
    "plt.ylabel(\"tSNE axis-2\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Reward')\n",
    "# plt.show()\n",
    "plt.savefig(\"tsne.png\")\n",
    "# ax[1].legend()\n",
    "# ax[1].set_xlim([-80, 80])\n",
    "# ax[1].set_ylim([-80, 80])\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "# for p in pos:\n",
    "    # ax.scatter(p[:, 0], p[:, 1], s=1)\n",
    "# ax.scatter(pos[:, 0], pos[:, 1], s=pos[:, 2] / 100)\n",
    "i = 1\n",
    "im = ax[i].scatter(pos[:, 0], pos[:, 1], c=np.log10(pos[:, 2]), s=2)\n",
    "ax[i].set_xlim([-185, 185])\n",
    "ax[i].set_ylim([-95, 5])\n",
    "ax[i].set_xlabel(\"Pan (deg)\")\n",
    "ax[i].set_ylabel(\"Tilt (deg)\")\n",
    "ax[i].set_aspect(\"equal\")\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('$\\log_{10}$ Zoom')\n",
    "i = 0\n",
    "im = ax[i].scatter(pos[:, 0], pos[:, 1], c=rewards, s=2, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "ax[i].set_xlim([-185, 185])\n",
    "ax[i].set_ylim([-95, 5])\n",
    "ax[i].set_xlabel(\"Pan (deg)\")\n",
    "ax[i].set_ylabel(\"Tilt (deg)\")\n",
    "ax[i].set_aspect(\"equal\")\n",
    "cbar = fig.colorbar(im)\n",
    "cbar.ax.set_ylabel('Reward')\n",
    "fig.savefig(\"pointings.png\")\n",
    "# plt.show()\n",
    "# fig.savefig(\"pointings.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f023e9-16d1-4aa4-ab65-93aa28deac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "# for p in pos:\n",
    "    # ax.scatter(p[:, 0], p[:, 1], s=1)\n",
    "im = ax.scatter(pos[:, 0], pos[:, 2], pos[:, 1], s=2, c=rewards, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "# ax.set_xlim([-185, 185])\n",
    "# ax.set_ylim([-95, 5])\n",
    "ax.set_xlabel(\"Pan (deg)\")\n",
    "ax.set_zlabel(\"Tilt (deg)\")\n",
    "ax.set_ylabel(\"Zoom\")\n",
    "fig.colorbar(im)\n",
    "# ax.set_aspect(\"equal\")\n",
    "# ax.set_ylim(700, 0)\n",
    "# fig.savefig(\"pointings.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e352b29-4284-4503-8e33-330639cb0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = (pos[:, 0] < -20) & (pos[:, 0] > -25) & (pos[:, 1] < -65) & (pos[:, 1] > -75)\n",
    "print(pos[sel], np.vstack(cmd)[sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265ff87-6106-41bb-b5ad-6d296af62259",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards[sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fd6b1-da22-41aa-b983-89a206c297af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.animation as animation\n",
    "\n",
    "# # pos = []\n",
    "# # for fn in fnames:\n",
    "# #     with open(pos_dir / f\"{fn}.txt\", \"r\") as f:\n",
    "# #         pos.append(np.array([l.strip().split(\",\") for l in f.readlines()], dtype=float))\n",
    "# # pos = np.vstack(pos)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "# ax.set_xlim([-185, 185])\n",
    "# ax.set_ylim([-95, 5])\n",
    "# ax.set_xlabel(\"Pan (deg)\")\n",
    "# ax.set_ylabel(\"Tilt (deg)\")\n",
    "# ax.set_aspect(\"equal\")\n",
    "# scat = ax.scatter(pos[0, 0], pos[0, 1], s=5, c='tab:red')\n",
    "\n",
    "\n",
    "# def animate(i):\n",
    "#     # if i < 5:\n",
    "#     #     for j in range(i-1):\n",
    "#     #         scat.plot(pos[j, 0], pos[j, 1], s=5)\n",
    "#     # else:\n",
    "#     # scat.set_offsets((pos[i, 0], pos[i, 1]))\n",
    "#     # for j in range(max(i-5, 0), i):\n",
    "#     # # if i > 0:\n",
    "#     ax.scatter(pos[i, 0], pos[i, 1], s=5, c='tab:red')\n",
    "#     return scat,\n",
    "\n",
    "# # def update(frame):\n",
    "# #     global positions\n",
    "# #     positions += velocities  # Update positions\n",
    "# #     lo = 0 if frame < 10 else frame - 10\n",
    "# #     for i in range(lo, frame):\n",
    "# #         scat.set_offsets(positions[i])\n",
    "# #     # Update the trails\n",
    "# #     for i in range(num_points):\n",
    "# #         trails[i].append(positions[i].copy())\n",
    "# #         if len(trails[i]) > 10:  # Limit trail length\n",
    "# #             trails[i].pop(0)\n",
    "\n",
    "# #     # Update the scatter plot\n",
    "# #     scatter.set_offsets(positions)\n",
    "\n",
    "# #     # Draw the trails\n",
    "# #     for trail in trails:\n",
    "# #         if len(trail) > 1:\n",
    "# #             trail_array = np.array(trail)\n",
    "# #             ax.plot(trail_array[:, 0], trail_array[:, 1], 'b-', alpha=0.5)\n",
    "\n",
    "# #     return scatter,\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, animate, repeat=True,\n",
    "#                                     frames=len(pos) - 1, interval=20)\n",
    "# # plt.show()\n",
    "# writer = animation.PillowWriter(fps=15,\n",
    "#                                 metadata=dict(artist='Me'),\n",
    "#                                 bitrate=1800)\n",
    "# ani.save('scatter.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99f66e-87d9-4ae8-b1c8-7e0470c111e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
