{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.datasets.ptz_dataset import PTZImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shandler = logging.StreamHandler()\n",
    "# shandler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "# shandler.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "# logger.addHandler(shandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/yufengluo/Research/anl/su24/up-PTZJEPA/configs/Config_file.yaml\", 'r') as fp:\n",
    "    params = yaml.load(fp, Loader=yaml.FullLoader)\n",
    "args = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_bfloat16 = args['meta']['use_bfloat16']\n",
    "model_name = args['meta']['model_name']\n",
    "load_model = args['meta']['load_checkpoint']\n",
    "r_file = args['meta']['read_checkpoint']\n",
    "copy_data = args['meta']['copy_data']\n",
    "pred_depth = args['meta']['pred_depth']\n",
    "pred_emb_dim = args['meta']['pred_emb_dim']\n",
    "camera_brand = args['meta']['camera_brand']\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "# -- DATA\n",
    "use_gaussian_blur = args['data']['use_gaussian_blur']\n",
    "use_horizontal_flip = args['data']['use_horizontal_flip']\n",
    "use_color_distortion = args['data']['use_color_distortion']\n",
    "color_jitter = args['data']['color_jitter_strength']\n",
    "# --\n",
    "global_batch_size = args['data']['global_batch_size']\n",
    "batch_size = args['data']['batch_size']\n",
    "pin_mem = args['data']['pin_mem']\n",
    "num_workers = args['data']['num_workers']\n",
    "root_path = args['data']['root_path']\n",
    "image_folder = args['data']['image_folder']\n",
    "crop_size = args['data']['crop_size']\n",
    "crop_scale = args['data']['crop_scale']\n",
    "# --\n",
    "\n",
    "# -- MASK\n",
    "allow_overlap = args['mask']['allow_overlap']  # whether to allow overlap b/w context and target blocks\n",
    "patch_size = args['mask']['patch_size']  # patch-size for model training\n",
    "num_enc_masks = args['mask']['num_enc_masks']  # number of context blocks\n",
    "min_keep = args['mask']['min_keep']  # min number of patches in context block\n",
    "enc_mask_scale = args['mask']['enc_mask_scale']  # scale of context blocks\n",
    "num_pred_masks = args['mask']['num_pred_masks']  # number of target blocks\n",
    "pred_mask_scale = args['mask']['pred_mask_scale']  # scale of target blocks\n",
    "aspect_ratio = args['mask']['aspect_ratio']  # aspect ratio of target blocks\n",
    "# --\n",
    "\n",
    "# -- OPTIMIZATION\n",
    "ema = args['optimization']['ema']\n",
    "ipe_scale = args['optimization']['ipe_scale']  # scheduler scale factor (def: 1.0)\n",
    "wd = float(args['optimization']['weight_decay'])\n",
    "final_wd = float(args['optimization']['final_weight_decay'])\n",
    "num_epochs = args['optimization']['epochs']\n",
    "warmup = args['optimization']['warmup']\n",
    "start_lr = args['optimization']['start_lr']\n",
    "lr = args['optimization']['lr']\n",
    "final_lr = args['optimization']['final_lr']\n",
    "\n",
    "# -- PLATEAU\n",
    "patience = args['plateau']['wm_patience']\n",
    "threshold = args['plateau']['wm_threshold']\n",
    "\n",
    "# -- LOGGING\n",
    "folder = args['logging']['folder']\n",
    "ownership_folder = args['logging']['ownership_folder']\n",
    "tag = args['logging']['write_tag']\n",
    "\n",
    "# -- MEMORY\n",
    "memory_models = args['memory']['models']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.helper' from '/Users/yufengluo/Research/anl/su24/up-PTZJEPA/notebooks/../source/helper.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import source\n",
    "import source.helper\n",
    "import importlib\n",
    "importlib.reload(source)\n",
    "importlib.reload(source.helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.helper import (\n",
    "    load_checkpoint,\n",
    "    init_model,\n",
    "    init_world_model,\n",
    "    init_opt)\n",
    "from source.transforms import make_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/yufengluo/Research/anl/su24/data/collected_imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_transforms:making ptz image data transforms\n"
     ]
    }
   ],
   "source": [
    "dataset = PTZImageDataset(data_dir, transform=make_transforms(to_tensor=True))\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, pos = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:source.helper:VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(4, 192, kernel_size=(14, 14), stride=(14, 14))\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder, predictor = init_world_model(\n",
    "    device=device,\n",
    "    patch_size=patch_size,\n",
    "    crop_size=crop_size,\n",
    "    pred_depth=pred_depth,\n",
    "    pred_emb_dim=pred_emb_dim,\n",
    "    model_name=model_name,\n",
    "    in_chans=4)\n",
    "target_encoder = copy.deepcopy(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 192])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoder(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.run_jepa import forward_context, arrange_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_imgs, context_poss, target_imgs, target_poss = arrange_inputs(img, pos, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          ...,\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440]],\n",
       " \n",
       "         [[ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          ...,\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440],\n",
       "          [ 0.1075,  0.1310,  0.4331,  ..., -0.6255, -0.0306,  0.3440]],\n",
       " \n",
       "         [[ 0.1016,  0.1288,  0.4331,  ..., -0.6296, -0.0164,  0.3493],\n",
       "          [ 0.1016,  0.1288,  0.4331,  ..., -0.6296, -0.0164,  0.3493],\n",
       "          [ 0.1016,  0.1288,  0.4331,  ..., -0.6296, -0.0164,  0.3493],\n",
       "          ...,\n",
       "          [ 0.1016,  0.1288,  0.4331,  ..., -0.6296, -0.0164,  0.3493],\n",
       "          [ 0.1016,  0.1288,  0.4331,  ..., -0.6296, -0.0164,  0.3493],\n",
       "          [ 0.1016,  0.1288,  0.4331,  ..., -0.6296, -0.0164,  0.3493]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1057,  0.1312,  0.4327,  ..., -0.6264, -0.0303,  0.3446],\n",
       "          [ 0.1057,  0.1312,  0.4327,  ..., -0.6264, -0.0303,  0.3446],\n",
       "          [ 0.1057,  0.1312,  0.4327,  ..., -0.6264, -0.0303,  0.3446],\n",
       "          ...,\n",
       "          [ 0.1057,  0.1312,  0.4327,  ..., -0.6264, -0.0303,  0.3446],\n",
       "          [ 0.1057,  0.1312,  0.4327,  ..., -0.6264, -0.0303,  0.3446],\n",
       "          [ 0.1057,  0.1312,  0.4327,  ..., -0.6264, -0.0303,  0.3446]],\n",
       " \n",
       "         [[ 0.0999,  0.1290,  0.4328,  ..., -0.6305, -0.0161,  0.3499],\n",
       "          [ 0.0999,  0.1290,  0.4328,  ..., -0.6305, -0.0161,  0.3499],\n",
       "          [ 0.0999,  0.1290,  0.4328,  ..., -0.6305, -0.0161,  0.3499],\n",
       "          ...,\n",
       "          [ 0.0999,  0.1290,  0.4328,  ..., -0.6305, -0.0161,  0.3499],\n",
       "          [ 0.0999,  0.1290,  0.4328,  ..., -0.6305, -0.0161,  0.3499],\n",
       "          [ 0.0999,  0.1290,  0.4328,  ..., -0.6305, -0.0161,  0.3499]],\n",
       " \n",
       "         [[ 0.0928,  0.1252,  0.4338,  ..., -0.6307, -0.0057,  0.3503],\n",
       "          [ 0.0928,  0.1252,  0.4338,  ..., -0.6307, -0.0057,  0.3503],\n",
       "          [ 0.0928,  0.1252,  0.4338,  ..., -0.6307, -0.0057,  0.3503],\n",
       "          ...,\n",
       "          [ 0.0928,  0.1252,  0.4338,  ..., -0.6307, -0.0057,  0.3503],\n",
       "          [ 0.0928,  0.1252,  0.4338,  ..., -0.6307, -0.0057,  0.3503],\n",
       "          [ 0.0928,  0.1252,  0.4338,  ..., -0.6307, -0.0057,  0.3503]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2877],\n",
       "          [-0.2877],\n",
       "          [-0.2877],\n",
       "          ...,\n",
       "          [-0.2877],\n",
       "          [-0.2877],\n",
       "          [-0.2877]],\n",
       " \n",
       "         [[-0.2877],\n",
       "          [-0.2877],\n",
       "          [-0.2877],\n",
       "          ...,\n",
       "          [-0.2877],\n",
       "          [-0.2877],\n",
       "          [-0.2877]],\n",
       " \n",
       "         [[-0.2953],\n",
       "          [-0.2953],\n",
       "          [-0.2953],\n",
       "          ...,\n",
       "          [-0.2953],\n",
       "          [-0.2953],\n",
       "          [-0.2953]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.2860],\n",
       "          [-0.2860],\n",
       "          [-0.2860],\n",
       "          ...,\n",
       "          [-0.2860],\n",
       "          [-0.2860],\n",
       "          [-0.2860]],\n",
       " \n",
       "         [[-0.2937],\n",
       "          [-0.2937],\n",
       "          [-0.2937],\n",
       "          ...,\n",
       "          [-0.2937],\n",
       "          [-0.2937],\n",
       "          [-0.2937]],\n",
       " \n",
       "         [[-0.2982],\n",
       "          [-0.2982],\n",
       "          [-0.2982],\n",
       "          ...,\n",
       "          [-0.2982],\n",
       "          [-0.2982],\n",
       "          [-0.2982]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_context(context_imgs, context_poss, target_poss, encoder, predictor, camera_brand, return_rewards=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
